## 📝Nvidia PeopleNet 정리

❓ PeopleNet이란?
NVIDIA PeopleNet은 이미지나 영상에서 사람, 가방, 얼굴 등 3가지 객체를 감지하는 AI 모델로, 사전 학습(pre-trained)된 객체 탐지(Object Detection) 전용 모델입니다.
딥러닝 기반으로 RGB 영상 내에서 사람을 빠르고 정확하게 찾아내어, 보안, 소매 분석, 군중 분석 등 다양한 분야에서 활용됩니다.

🤔 쉽게 말하면?
카메라 영상, 사진 속에서 사람·가방·얼굴이 어디에 있는지 자동으로 찾아주는 프로그램입니다.

컴퓨터가 영상/이미지를 보고 “여기 사람이 있다!”고 사람의 눈처럼 인식하는 기능입니다.

바운딩 박스를 그려 위치와 신뢰도를 함께 제공합니다.
🎯 핵심 기능
| 기능         | 설명                                                        |
|--------------|-------------------------------------------------------------|
| 사람 감지     | 영상/사진 등에서 ‘사람’ 객체를 신속하게 탐지                |
| 위치 표시     | 찾은 객체 주변에 네모(바운딩 박스)로 위치 표시               |
| 실시간 처리   | 라이브 스트림/실시간 동영상에서도 빠르게 감지 가능            |
| 신뢰도 측정   | 감지한 객체의 신뢰도를 점수(confidence)로 제공              |
| 다중 클래스   | 사람(person), 가방(bag), 얼굴(face) 등 동시 감지            |

🏗️ 기술 구조: NVIDIA TAO 툴킷 기반 아키텍처
DetectNet_v2 기반, ResNet34 백본이 특징 추출기에 사용됨
‘GridBox’ 방식: 입력 영상을 격자(grid, 예: 60x34)로 나눠 각 셀마다 바운딩 박스(xc, yc, w, h)와 신뢰도를 예측
출력 결과(바운딩 박스 좌표+클래스+신뢰도)는 후처리(NMS 또는 DBSCAN) 단계를 거쳐 실제 객체만 남김
입력: 960×544 크기(RGB, NCHW 포맷)

🚦 동작 방식 한눈에 보기
이미지를 입력 → CNN이 특징 맵 추출
격자별로 객체 바운딩 박스와 신뢰도 예측
Non-Maximum Suppression(NMS) 등 후처리로 중복 감지 제거
최종 바운딩 박스를 원본 영상에 맞게 좌표 변환해 결과 반환

🔬 특징 및 제한점
사람 감지가 최우선이며, 가방/얼굴 클래스는 보조적 용도 (정확도는 사람보다 낮을 수 있음)
밝은 조명, 깨끗한 RGB 영상에서 최적 성능 발휘
실내/실외 광범위하게 활용 가능
어두운 환경, 흑백/IR, 블러, 어안 렌즈 등 특수 상황에선 오탐/미탐 가능
INT8 양자화(Quantized) 모델 제공 → 더 빠른 추론, 경량화에 유리함
커스텀 데이터셋을 통한 추가 학습(transfer learning/fine-tuning) 가능 (NVIDIA TAO로 지원)
DeepStream, Jetson 등 NVIDIA SW/hardware와 높은 호환성

💻 클라우드/로컬 환경 활용 예시
Runpods, Colab, Jetson, 데스크탑, 서버 등 다양한 환경에서
ONNX Runtime 또는 TensorRT로 실시간 객체 인식 가능
yt-dlp로 유튜브 영상 가져와 프레임별 사람 검출 실험
Python 클래스 형태 코드로 디버깅/로깅 삽입 및 커스터마이징 쉬움
Ubuntu 22.04 컨테이너 환경에서 PeopleNet ONNX(INT8) 모델을 테스트하고 디버깅하는 코드.  


> - 시스템 의존성 설치  
> - NGC CLI 다운로드/설정  
> - Python 패키지 설치  
> - YouTube 샘플 영상 다운로드  

---

## 0. 환경 개요
| 항목 | 값 |
|------|----|
| OS | Ubuntu 22.04 |
| 핵심 라이브러리 | OpenCV 4.12, ONNX-Runtime 1.22.1, yt-dlp |

---
### 실습 정리
<details> 
<summary>더보기</summary>strong>
 1. 셀 | 시스템 패키지 설치

```

# APT 인덱스 갱신 후 필수 패키지 설치
apt update && apt install -y unzip wget ffmpeg
# ㆍunzip  : NGC CLI ZIP 압축 해제용
# ㆍwget   : 원격 파일 다운로드
# ㆍffmpeg : YouTube MP4 코덱 호환‧프레임 추출

```

2. 셀 | 작업 디렉터리 확인

```

# 현재 디렉터리(컨테이너 기본 경로) 확인
pwd      # 예상 출력: /workspace

```

3. 셀 | 기존 NGC CLI 탐색

```
# 이미 NGC CLI 가 설치되어 있는지 검색
find /workspace -name "*ngc*" -type f
```

4. 셀 | NGC CLI 다운로드

```
# NVIDIA 공식 사이트에서 CLI ZIP 받아오기
wget -q https://ngc.nvidia.com/downloads/ngccli_reg_linux.zip
```

5. 셀 | NGC CLI 압축 해제

```
# ZIP 파일 풀어서 ./ngc-cli/ 디렉터리 생성
unzip ngccli_reg_linux.zip
```

6. 셀 | Python 라이브러리 설치

```
# PeopleNet 추론 및 YouTube 다운로드용 파이썬 패키지
pip install onnxruntime yt-dlp opencv-python numpy
# ㆍonnxruntime : ONNX 모델 추론 엔진
# ㆍyt-dlp      : YouTube 영상 다운로드
# ㆍopencv-python: 프레임 처리·시각화
# ㆍnumpy       : 수치 연산
```

7. 셀 | PeopleNet 디버그 실행

```
############################################################
# DebugNVIDIAPeopleNet 클래스 정의 및 5-프레임 테스트 실행 #
############################################################
import cv2, numpy as np, subprocess, os, onnxruntime as ort, yt_dlp

class DebugNVIDIAPeopleNet:
    def __init__(self):
        print("🚀 디버깅 NVIDIA PeopleNet 시작...")
        # ① 모델 경로 및 클래스/색상 정의
        self.model_path = (
            "/workspace/peoplenet_vpruned_quantized_decrypted_v2.3.4/"
            "resnet34_peoplenet_int8.onnx"
        )
        self.classes = ['person', 'bag', 'face']
        self.colors  = [(0,255,0), (255,0,0), (0,0,255)]
        # ② 모델 로드
        self.setup_model()

    # ---------------- 모델 로드 & 더미 추론 ---------------- #
    def setup_model(self):
        print(f"📁 모델 경로 확인: {self.model_path}")
        if not os.path.exists(self.model_path):
            return self._find_model()
        # CPUExecutionProvider → 필요시 CUDAExecutionProvider 로 변경
        self.session = ort.InferenceSession(
            self.model_path, providers=['CPUExecutionProvider']
        )
        self.input_name  = self.session.get_inputs()[0].name
        self.output_names = [o.name for o in self.session.get_outputs()]
        print("✅ 모델 로드 완료, 더미 테스트 실행")
        self._test_inference()

    def _test_inference(self):
        dummy = np.random.randn(1,3,544,960).astype(np.float32)
        outs  = self.session.run(self.output_names, {self.input_name: dummy})
        for idx, o in enumerate(outs):
            print(f"  ↳ 출력{idx}: {o.shape}, 값범위 [{o.min():.3f}, {o.max():.3f}]")

    # ------------------- 전처리 & 추론 -------------------- #
    def _preprocess(self, frame):
        f = cv2.resize(frame,(960,544))
        f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB).astype(np.float32)/255.0
        f = np.transpose(f,(2,0,1))[None,...]     # (1,3,544,960)
        return f

    def detect(self, frame):
        inp = self._preprocess(frame)
        outs = self.session.run(self.output_names,{self.input_name: inp})
        return self._postprocess(outs[0], frame.shape)

    # ---------------- 후처리 (임계값+NMS) ------------------ #
    def _postprocess(self, pred, oshape):
        if pred.ndim==4: pred = pred[0]           # (3,34,60)
        H,W = oshape[:2]
        detections = []
        for cid, cname in enumerate(self.classes):
            grid = pred[cid]; thr=0.1
            ys,xs = np.where(grid>thr)
            for y,x in zip(ys[:5], xs[:5]):       # 상위 5개만
                conf = float(grid[y,x])
                cx,cy = (x+0.5)/60, (y+0.5)/34
                bw,bh = (0.12,0.20) if cname=='person' else \
                        (0.06,0.08) if cname=='bag'    else (0.04,0.05)
                x1,y1 = int((cx-bw/2)*W), int((cy-bh/2)*H)
                x2,y2 = int((cx+bw/2)*W), int((cy+bh/2)*H)
                detections.append(
                    dict(bbox=[x1,y1,x2,y2], confidence=conf,
                         class_id=cid, class_=cname)
                )
        return detections

    # ------------------- 유튜브 다운로드 ------------------- #
    @staticmethod
    def download_mp4(url):
        out = "/workspace/debug_input_video.mp4"
        subprocess.run(["yt-dlp","-f","best[height<=720]","-o",out,url],
                       check=True)
        return out if os.path.exists(out) else None

# ---------------------- 런처 ----------------------------- #
def run_debug():
    dbg = DebugNVIDIAPeopleNet()
    video = dbg.download_mp4("https://www.youtube.com/watch?v=SzRzYvQq0aQ")
    cap = cv2.VideoCapture(video); frame_ids = [0,100,200,300,400]
    for fid in frame_ids:
        cap.set(cv2.CAP_PROP_POS_FRAMES,fid)
        ok,frame = cap.read();  print(f"\n🎯 Frame {fid}")
        if ok:
            dets = dbg.detect(frame)
            for d in dets:
                print(f"  → {d['class_']} {d['confidence']:.3f}")
    cap.release()

# 5개 프레임 샘플 검출 실행
run_debug()

```

</strong></summary>

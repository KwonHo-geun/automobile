## ğŸ“Nvidia PeopleNet ì •ë¦¬

â“ PeopleNetì´ë€?
NVIDIA PeopleNetì€ ì´ë¯¸ì§€ë‚˜ ì˜ìƒì—ì„œ ì‚¬ëŒ, ê°€ë°©, ì–¼êµ´ ë“± 3ê°€ì§€ ê°ì²´ë¥¼ ê°ì§€í•˜ëŠ” AI ëª¨ë¸ë¡œ, ì‚¬ì „ í•™ìŠµ(pre-trained)ëœ ê°ì²´ íƒì§€(Object Detection) ì „ìš© ëª¨ë¸ì…ë‹ˆë‹¤.
ë”¥ëŸ¬ë‹ ê¸°ë°˜ìœ¼ë¡œ RGB ì˜ìƒ ë‚´ì—ì„œ ì‚¬ëŒì„ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì°¾ì•„ë‚´ì–´, ë³´ì•ˆ, ì†Œë§¤ ë¶„ì„, êµ°ì¤‘ ë¶„ì„ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.

ğŸ¤” ì‰½ê²Œ ë§í•˜ë©´?
ì¹´ë©”ë¼ ì˜ìƒ, ì‚¬ì§„ ì†ì—ì„œ ì‚¬ëŒÂ·ê°€ë°©Â·ì–¼êµ´ì´ ì–´ë””ì— ìˆëŠ”ì§€ ìë™ìœ¼ë¡œ ì°¾ì•„ì£¼ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.

ì»´í“¨í„°ê°€ ì˜ìƒ/ì´ë¯¸ì§€ë¥¼ ë³´ê³  â€œì—¬ê¸° ì‚¬ëŒì´ ìˆë‹¤!â€ê³  ì‚¬ëŒì˜ ëˆˆì²˜ëŸ¼ ì¸ì‹í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.

ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë ¤ ìœ„ì¹˜ì™€ ì‹ ë¢°ë„ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.
ğŸ¯ í•µì‹¬ ê¸°ëŠ¥
| ê¸°ëŠ¥         | ì„¤ëª…                                                        |
|--------------|-------------------------------------------------------------|
| ì‚¬ëŒ ê°ì§€     | ì˜ìƒ/ì‚¬ì§„ ë“±ì—ì„œ â€˜ì‚¬ëŒâ€™ ê°ì²´ë¥¼ ì‹ ì†í•˜ê²Œ íƒì§€                |
| ìœ„ì¹˜ í‘œì‹œ     | ì°¾ì€ ê°ì²´ ì£¼ë³€ì— ë„¤ëª¨(ë°”ìš´ë”© ë°•ìŠ¤)ë¡œ ìœ„ì¹˜ í‘œì‹œ               |
| ì‹¤ì‹œê°„ ì²˜ë¦¬   | ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¼/ì‹¤ì‹œê°„ ë™ì˜ìƒì—ì„œë„ ë¹ ë¥´ê²Œ ê°ì§€ ê°€ëŠ¥            |
| ì‹ ë¢°ë„ ì¸¡ì •   | ê°ì§€í•œ ê°ì²´ì˜ ì‹ ë¢°ë„ë¥¼ ì ìˆ˜(confidence)ë¡œ ì œê³µ              |
| ë‹¤ì¤‘ í´ë˜ìŠ¤   | ì‚¬ëŒ(person), ê°€ë°©(bag), ì–¼êµ´(face) ë“± ë™ì‹œ ê°ì§€            |

ğŸ—ï¸ ê¸°ìˆ  êµ¬ì¡°: NVIDIA TAO íˆ´í‚· ê¸°ë°˜ ì•„í‚¤í…ì²˜
DetectNet_v2 ê¸°ë°˜, ResNet34 ë°±ë³¸ì´ íŠ¹ì§• ì¶”ì¶œê¸°ì— ì‚¬ìš©ë¨
â€˜GridBoxâ€™ ë°©ì‹: ì…ë ¥ ì˜ìƒì„ ê²©ì(grid, ì˜ˆ: 60x34)ë¡œ ë‚˜ëˆ  ê° ì…€ë§ˆë‹¤ ë°”ìš´ë”© ë°•ìŠ¤(xc, yc, w, h)ì™€ ì‹ ë¢°ë„ë¥¼ ì˜ˆì¸¡
ì¶œë ¥ ê²°ê³¼(ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ+í´ë˜ìŠ¤+ì‹ ë¢°ë„)ëŠ” í›„ì²˜ë¦¬(NMS ë˜ëŠ” DBSCAN) ë‹¨ê³„ë¥¼ ê±°ì³ ì‹¤ì œ ê°ì²´ë§Œ ë‚¨ê¹€
ì…ë ¥: 960Ã—544 í¬ê¸°(RGB, NCHW í¬ë§·)

ğŸš¦ ë™ì‘ ë°©ì‹ í•œëˆˆì— ë³´ê¸°
ì´ë¯¸ì§€ë¥¼ ì…ë ¥ â†’ CNNì´ íŠ¹ì§• ë§µ ì¶”ì¶œ
ê²©ìë³„ë¡œ ê°ì²´ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì˜ˆì¸¡
Non-Maximum Suppression(NMS) ë“± í›„ì²˜ë¦¬ë¡œ ì¤‘ë³µ ê°ì§€ ì œê±°
ìµœì¢… ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì›ë³¸ ì˜ìƒì— ë§ê²Œ ì¢Œí‘œ ë³€í™˜í•´ ê²°ê³¼ ë°˜í™˜

ğŸ”¬ íŠ¹ì§• ë° ì œí•œì 
ì‚¬ëŒ ê°ì§€ê°€ ìµœìš°ì„ ì´ë©°, ê°€ë°©/ì–¼êµ´ í´ë˜ìŠ¤ëŠ” ë³´ì¡°ì  ìš©ë„ (ì •í™•ë„ëŠ” ì‚¬ëŒë³´ë‹¤ ë‚®ì„ ìˆ˜ ìˆìŒ)
ë°ì€ ì¡°ëª…, ê¹¨ë—í•œ RGB ì˜ìƒì—ì„œ ìµœì  ì„±ëŠ¥ ë°œíœ˜
ì‹¤ë‚´/ì‹¤ì™¸ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš© ê°€ëŠ¥
ì–´ë‘ìš´ í™˜ê²½, í‘ë°±/IR, ë¸”ëŸ¬, ì–´ì•ˆ ë Œì¦ˆ ë“± íŠ¹ìˆ˜ ìƒí™©ì—ì„  ì˜¤íƒ/ë¯¸íƒ ê°€ëŠ¥
INT8 ì–‘ìí™”(Quantized) ëª¨ë¸ ì œê³µ â†’ ë” ë¹ ë¥¸ ì¶”ë¡ , ê²½ëŸ‰í™”ì— ìœ ë¦¬í•¨
ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ í†µí•œ ì¶”ê°€ í•™ìŠµ(transfer learning/fine-tuning) ê°€ëŠ¥ (NVIDIA TAOë¡œ ì§€ì›)
DeepStream, Jetson ë“± NVIDIA SW/hardwareì™€ ë†’ì€ í˜¸í™˜ì„±

ğŸ’» í´ë¼ìš°ë“œ/ë¡œì»¬ í™˜ê²½ í™œìš© ì˜ˆì‹œ
Runpods, Colab, Jetson, ë°ìŠ¤í¬íƒ‘, ì„œë²„ ë“± ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ
ONNX Runtime ë˜ëŠ” TensorRTë¡œ ì‹¤ì‹œê°„ ê°ì²´ ì¸ì‹ ê°€ëŠ¥
yt-dlpë¡œ ìœ íŠœë¸Œ ì˜ìƒ ê°€ì ¸ì™€ í”„ë ˆì„ë³„ ì‚¬ëŒ ê²€ì¶œ ì‹¤í—˜
Python í´ë˜ìŠ¤ í˜•íƒœ ì½”ë“œë¡œ ë””ë²„ê¹…/ë¡œê¹… ì‚½ì… ë° ì»¤ìŠ¤í„°ë§ˆì´ì§• ì‰¬ì›€
Ubuntu 22.04 ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œ PeopleNet ONNX(INT8) ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ì½”ë“œ.  


> - ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜  
> - NGC CLI ë‹¤ìš´ë¡œë“œ/ì„¤ì •  
> - Python íŒ¨í‚¤ì§€ ì„¤ì¹˜  
> - YouTube ìƒ˜í”Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ  

---

## 0. í™˜ê²½ ê°œìš”
| í•­ëª© | ê°’ |
|------|----|
| OS | Ubuntu 22.04 |
| í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ | OpenCV 4.12, ONNX-Runtime 1.22.1, yt-dlp |

---
### ì‹¤ìŠµ ì •ë¦¬
<details> 
<summary>ë”ë³´ê¸°</summary>strong>
 1. ì…€ | ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```

# APT ì¸ë±ìŠ¤ ê°±ì‹  í›„ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
apt update && apt install -y unzip wget ffmpeg
# ã†unzip  : NGC CLI ZIP ì••ì¶• í•´ì œìš©
# ã†wget   : ì›ê²© íŒŒì¼ ë‹¤ìš´ë¡œë“œ
# ã†ffmpeg : YouTube MP4 ì½”ë± í˜¸í™˜â€§í”„ë ˆì„ ì¶”ì¶œ

```

2. ì…€ | ì‘ì—… ë””ë ‰í„°ë¦¬ í™•ì¸

```

# í˜„ì¬ ë””ë ‰í„°ë¦¬(ì»¨í…Œì´ë„ˆ ê¸°ë³¸ ê²½ë¡œ) í™•ì¸
pwd      # ì˜ˆìƒ ì¶œë ¥: /workspace

```

3. ì…€ | ê¸°ì¡´ NGC CLI íƒìƒ‰

```
# ì´ë¯¸ NGC CLI ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ ê²€ìƒ‰
find /workspace -name "*ngc*" -type f
```

4. ì…€ | NGC CLI ë‹¤ìš´ë¡œë“œ

```
# NVIDIA ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ CLI ZIP ë°›ì•„ì˜¤ê¸°
wget -q https://ngc.nvidia.com/downloads/ngccli_reg_linux.zip
```

5. ì…€ | NGC CLI ì••ì¶• í•´ì œ

```
# ZIP íŒŒì¼ í’€ì–´ì„œ ./ngc-cli/ ë””ë ‰í„°ë¦¬ ìƒì„±
unzip ngccli_reg_linux.zip
```

6. ì…€ | Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```
# PeopleNet ì¶”ë¡  ë° YouTube ë‹¤ìš´ë¡œë“œìš© íŒŒì´ì¬ íŒ¨í‚¤ì§€
pip install onnxruntime yt-dlp opencv-python numpy
# ã†onnxruntime : ONNX ëª¨ë¸ ì¶”ë¡  ì—”ì§„
# ã†yt-dlp      : YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ
# ã†opencv-python: í”„ë ˆì„ ì²˜ë¦¬Â·ì‹œê°í™”
# ã†numpy       : ìˆ˜ì¹˜ ì—°ì‚°
```

7. ì…€ | PeopleNet ë””ë²„ê·¸ ì‹¤í–‰

```
############################################################
# DebugNVIDIAPeopleNet í´ë˜ìŠ¤ ì •ì˜ ë° 5-í”„ë ˆì„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ #
############################################################
import cv2, numpy as np, subprocess, os, onnxruntime as ort, yt_dlp

class DebugNVIDIAPeopleNet:
    def __init__(self):
        print("ğŸš€ ë””ë²„ê¹… NVIDIA PeopleNet ì‹œì‘...")
        # â‘  ëª¨ë¸ ê²½ë¡œ ë° í´ë˜ìŠ¤/ìƒ‰ìƒ ì •ì˜
        self.model_path = (
            "/workspace/peoplenet_vpruned_quantized_decrypted_v2.3.4/"
            "resnet34_peoplenet_int8.onnx"
        )
        self.classes = ['person', 'bag', 'face']
        self.colors  = [(0,255,0), (255,0,0), (0,0,255)]
        # â‘¡ ëª¨ë¸ ë¡œë“œ
        self.setup_model()

    # ---------------- ëª¨ë¸ ë¡œë“œ & ë”ë¯¸ ì¶”ë¡  ---------------- #
    def setup_model(self):
        print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ í™•ì¸: {self.model_path}")
        if not os.path.exists(self.model_path):
            return self._find_model()
        # CPUExecutionProvider â†’ í•„ìš”ì‹œ CUDAExecutionProvider ë¡œ ë³€ê²½
        self.session = ort.InferenceSession(
            self.model_path, providers=['CPUExecutionProvider']
        )
        self.input_name  = self.session.get_inputs()[0].name
        self.output_names = [o.name for o in self.session.get_outputs()]
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ, ë”ë¯¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        self._test_inference()

    def _test_inference(self):
        dummy = np.random.randn(1,3,544,960).astype(np.float32)
        outs  = self.session.run(self.output_names, {self.input_name: dummy})
        for idx, o in enumerate(outs):
            print(f"  â†³ ì¶œë ¥{idx}: {o.shape}, ê°’ë²”ìœ„ [{o.min():.3f}, {o.max():.3f}]")

    # ------------------- ì „ì²˜ë¦¬ & ì¶”ë¡  -------------------- #
    def _preprocess(self, frame):
        f = cv2.resize(frame,(960,544))
        f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB).astype(np.float32)/255.0
        f = np.transpose(f,(2,0,1))[None,...]     # (1,3,544,960)
        return f

    def detect(self, frame):
        inp = self._preprocess(frame)
        outs = self.session.run(self.output_names,{self.input_name: inp})
        return self._postprocess(outs[0], frame.shape)

    # ---------------- í›„ì²˜ë¦¬ (ì„ê³„ê°’+NMS) ------------------ #
    def _postprocess(self, pred, oshape):
        if pred.ndim==4: pred = pred[0]           # (3,34,60)
        H,W = oshape[:2]
        detections = []
        for cid, cname in enumerate(self.classes):
            grid = pred[cid]; thr=0.1
            ys,xs = np.where(grid>thr)
            for y,x in zip(ys[:5], xs[:5]):       # ìƒìœ„ 5ê°œë§Œ
                conf = float(grid[y,x])
                cx,cy = (x+0.5)/60, (y+0.5)/34
                bw,bh = (0.12,0.20) if cname=='person' else \
                        (0.06,0.08) if cname=='bag'    else (0.04,0.05)
                x1,y1 = int((cx-bw/2)*W), int((cy-bh/2)*H)
                x2,y2 = int((cx+bw/2)*W), int((cy+bh/2)*H)
                detections.append(
                    dict(bbox=[x1,y1,x2,y2], confidence=conf,
                         class_id=cid, class_=cname)
                )
        return detections

    # ------------------- ìœ íŠœë¸Œ ë‹¤ìš´ë¡œë“œ ------------------- #
    @staticmethod
    def download_mp4(url):
        out = "/workspace/debug_input_video.mp4"
        subprocess.run(["yt-dlp","-f","best[height<=720]","-o",out,url],
                       check=True)
        return out if os.path.exists(out) else None

# ---------------------- ëŸ°ì²˜ ----------------------------- #
def run_debug():
    dbg = DebugNVIDIAPeopleNet()
    video = dbg.download_mp4("https://www.youtube.com/watch?v=SzRzYvQq0aQ")
    cap = cv2.VideoCapture(video); frame_ids = [0,100,200,300,400]
    for fid in frame_ids:
        cap.set(cv2.CAP_PROP_POS_FRAMES,fid)
        ok,frame = cap.read();  print(f"\nğŸ¯ Frame {fid}")
        if ok:
            dets = dbg.detect(frame)
            for d in dets:
                print(f"  â†’ {d['class_']} {d['confidence']:.3f}")
    cap.release()

# 5ê°œ í”„ë ˆì„ ìƒ˜í”Œ ê²€ì¶œ ì‹¤í–‰
run_debug()

```

</strong></summary>

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonHo-geun/automobile/blob/main/25.07.28_Pytorch%26ONNX%EB%B9%84%EA%B5%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G04wQwspXms0",
        "outputId": "630f98b6-a7df-4943-a3ff-29e8fbc5a9c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP 파일을 코랩으로 복사\n",
        "!cp \"/content/drive/MyDrive/07_28_automobiledataset.zip\" \"/content/\"\n",
        "\n",
        "# 압축 해제\n",
        "!unzip -o /content/07_28_automobiledataset.zip -d /content/\n",
        "\n",
        "# 압축 해제 확인\n",
        "!ls -la /content/"
      ],
      "metadata": {
        "id": "Pj0VqbznXgLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ultralytics 설치\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "kiF72AsIZ3aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 설치 확인 후 다시 실행\n",
        "from ultralytics import YOLO\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\"✅ ultralytics 설치 완료!\")\n",
        "\n",
        "# 이미 학습된 모델 사용\n",
        "model = YOLO('/content/dataset/best.pt')\n",
        "\n",
        "# YouTube 영상 다운로드\n",
        "!pip install yt-dlp\n",
        "!yt-dlp -f 'best[height<=720]' -o '/content/test_video.%(ext)s' 'https://www.youtube.com/watch?v=AxLmroTo3rQ'\n",
        "\n",
        "# 다운로드된 파일 찾기 (확장자가 다를 수 있음)\n",
        "video_files = glob.glob('/content/test_video.*')\n",
        "if video_files:\n",
        "    video_path = video_files[0]\n",
        "    print(f\"📹 다운로드된 영상: {video_path}\")\n",
        "\n",
        "    # 추론 실행\n",
        "    results = model(video_path)\n",
        "\n",
        "    # 결과 표시 (영상의 경우 첫 번째 프레임만)\n",
        "    if results:\n",
        "        results[0].show()\n",
        "else:\n",
        "    print(\"❌ 영상 다운로드 실패\")\n",
        "\n",
        "# 기존 검증 데이터로 성능 측정\n",
        "print(\"\\n📊 모델 성능 평가:\")\n",
        "metrics = model.val(data='/content/dataset/dataset.yaml')\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "\n",
        "print(\"\\n✅ 모든 작업 완료!\")"
      ],
      "metadata": {
        "id": "9LXE0I1YXgF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "yaml 파일 수정\n",
        "path: /content/dataset\n",
        "train: train/images\n",
        "val: valid/images\n",
        "names:\n",
        "  0: lane\n",
        "  1: traffic_sign\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "F0cCaOOehsBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. dataset.yaml 파일 내용 확인\n",
        "print(\"📋 dataset.yaml 파일 내용:\")\n",
        "with open('/content/dataset/dataset.yaml', 'r') as f:\n",
        "    yaml_content = f.read()\n",
        "    print(yaml_content)"
      ],
      "metadata": {
        "id": "dNYHSQGjXf_z",
        "outputId": "8492073b-fef2-48b9-ce11-62273985b462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📋 dataset.yaml 파일 내용:\n",
            "path: /content/dataset\n",
            "train: train/images\n",
            "val: valid/images\n",
            "names:\n",
            "  0: lane\n",
            "  1: traffic_sign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics yt-dlp"
      ],
      "metadata": {
        "id": "RhjQKmNxaoSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import glob\n",
        "\n",
        "# yaml 수정 (핵심 문제 해결)\n",
        "yaml_fix = '''path: /content/dataset\n",
        "train: train/images\n",
        "val: valid/images\n",
        "names:\n",
        "  0: lane\n",
        "  1: traffic_sign\n",
        "nc: 2'''\n",
        "\n",
        "with open('/content/dataset/dataset.yaml', 'w') as f:\n",
        "    f.write(yaml_fix)\n",
        "\n",
        "# 모델 로드 & 영상 다운로드 & 추론\n",
        "model = YOLO('/content/dataset/best.pt')\n",
        "!yt-dlp -f 'best[height<=720]' -o '/content/test_video.%(ext)s' 'https://www.youtube.com/watch?v=AxLmroTo3rQ'\n",
        "\n",
        "video_path = glob.glob('/content/test_video.*')[0]\n",
        "results = model(video_path)\n",
        "results[0].show()\n",
        "\n",
        "# 성능 평가\n",
        "metrics = model.val(data='/content/dataset/dataset.yaml')\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")"
      ],
      "metadata": {
        "id": "d_FKpd8eXf5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install ultralytics yt-dlp\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import Video\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "print(\"🚀 TensorRT 최적화 YOLO 추론 시작!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1️⃣ 기본 모델들 로드\n",
        "print(\"🤖 기본 모델 로드 중...\")\n",
        "base_model = YOLO('yolo11n.pt')\n",
        "custom_model = YOLO('/content/dataset/best.pt')\n",
        "\n",
        "print(f\"기본 모델 클래스 수: {len(base_model.names)}\")\n",
        "print(f\"커스텀 모델 클래스 수: {len(custom_model.names)}\")\n",
        "\n",
        "# 2️⃣ TensorRT로 변환\n",
        "print(\"\\n⚡ TensorRT 변환 중...\")\n",
        "print(\"기본 모델 → TensorRT 변환...\")\n",
        "base_model.export(format='engine', half=True, device=0)  # FP16 최적화\n",
        "base_trt_path = 'yolo11n.engine'\n",
        "\n",
        "print(\"커스텀 모델 → TensorRT 변환...\")\n",
        "custom_model.export(format='engine', half=True, device=0)\n",
        "custom_trt_path = '/content/dataset/best.engine'\n",
        "\n",
        "# 3️⃣ TensorRT 모델 로드\n",
        "print(\"\\n🔥 TensorRT 모델 로드 중...\")\n",
        "base_trt_model = YOLO(base_trt_path)\n",
        "custom_trt_model = YOLO(custom_trt_path)\n",
        "\n",
        "print(\"✅ TensorRT 모델 로드 완료!\")\n",
        "\n",
        "# 4️⃣ 영상 다운로드\n",
        "print(\"\\n📥 YouTube 영상 다운로드 중...\")\n",
        "!yt-dlp -f 'best[height<=720]' -o '/content/test_video.%(ext)s' 'https://www.youtube.com/watch?v=AxLmroTo3rQ'\n",
        "\n",
        "video_path = glob.glob('/content/test_video.*')[0]\n",
        "print(f\"✅ 다운로드 완료: {video_path}\")\n",
        "\n",
        "# 5️⃣ 성능 비교 함수\n",
        "def performance_comparison(video_path, frames_to_test=100):\n",
        "    \"\"\"PyTorch vs TensorRT 성능 비교\"\"\"\n",
        "\n",
        "    print(f\"\\n⏱️ 성능 비교 (첫 {frames_to_test}프레임)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # PyTorch 모델 성능 테스트\n",
        "    pytorch_times = []\n",
        "    for i in range(frames_to_test):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        start_time = time.time()\n",
        "        _ = base_model(frame, verbose=False)\n",
        "        _ = custom_model(frame, verbose=False)\n",
        "        end_time = time.time()\n",
        "\n",
        "        pytorch_times.append(end_time - start_time)\n",
        "\n",
        "    # TensorRT 모델 성능 테스트\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # 처음으로 되돌리기\n",
        "    tensorrt_times = []\n",
        "    for i in range(frames_to_test):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        start_time = time.time()\n",
        "        _ = base_trt_model(frame, verbose=False)\n",
        "        _ = custom_trt_model(frame, verbose=False)\n",
        "        end_time = time.time()\n",
        "\n",
        "        tensorrt_times.append(end_time - start_time)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # 결과 출력\n",
        "    pytorch_avg = np.mean(pytorch_times) * 1000  # ms로 변환\n",
        "    tensorrt_avg = np.mean(tensorrt_times) * 1000\n",
        "    speedup = pytorch_avg / tensorrt_avg\n",
        "\n",
        "    print(f\"🐍 PyTorch 평균: {pytorch_avg:.2f}ms/frame ({1000/pytorch_avg:.1f} FPS)\")\n",
        "    print(f\"⚡ TensorRT 평균: {tensorrt_avg:.2f}ms/frame ({1000/tensorrt_avg:.1f} FPS)\")\n",
        "    print(f\"🚀 속도 향상: {speedup:.2f}x\")\n",
        "\n",
        "    return speedup\n",
        "\n",
        "# 성능 비교 실행\n",
        "speedup_ratio = performance_comparison(video_path)\n",
        "\n",
        "# 6️⃣ TensorRT 최적화된 결합 추론\n",
        "def tensorrt_combined_inference(video_path, output_path='/content/tensorrt_result.mp4'):\n",
        "    \"\"\"TensorRT 최적화된 결합 추론\"\"\"\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # 출력 영상 설정\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    print(f\"\\n🎬 TensorRT 최적화 영상 처리 중... (총 {total_frames} 프레임)\")\n",
        "\n",
        "    frame_count = 0\n",
        "    total_inference_time = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # TensorRT 추론 (시간 측정)\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 기본 TensorRT 모델 추론\n",
        "        base_results = base_trt_model(frame, verbose=False)\n",
        "\n",
        "        # 커스텀 TensorRT 모델 추론\n",
        "        custom_results = custom_trt_model(frame, verbose=False)\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "        total_inference_time += inference_time\n",
        "\n",
        "        # 결과 시각화\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        # 기본 YOLO 결과 그리기 (파란색)\n",
        "        if base_results[0].boxes is not None:\n",
        "            for box in base_results[0].boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "\n",
        "                if conf > 0.3:\n",
        "                    label = f\"{base_trt_model.names[cls]} {conf:.2f}\"\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # 커스텀 YOLO 결과 그리기 (빨간색)\n",
        "        if custom_results[0].boxes is not None:\n",
        "            for box in custom_results[0].boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "\n",
        "                if conf > 0.3:\n",
        "                    label = f\"{custom_trt_model.names[cls]} {conf:.2f}\"\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        # TensorRT 정보 표시\n",
        "        fps_text = f\"TensorRT: {1/inference_time:.1f} FPS\"\n",
        "        cv2.putText(annotated_frame, fps_text, (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        out.write(annotated_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "        if frame_count % 50 == 0:\n",
        "            avg_fps = frame_count / total_inference_time\n",
        "            print(f\"   처리 중... {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%) - 평균 {avg_fps:.1f} FPS\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    avg_fps = frame_count / total_inference_time\n",
        "    print(f\"✅ TensorRT 결과 영상 저장: {output_path}\")\n",
        "    print(f\"📊 평균 처리 속도: {avg_fps:.1f} FPS\")\n",
        "\n",
        "    return avg_fps\n",
        "\n",
        "# 7️⃣ TensorRT 최적화된 추론 실행\n",
        "print(\"\\n🔥 TensorRT 최적화된 결합 추론 실행...\")\n",
        "tensorrt_fps = tensorrt_combined_inference(video_path, '/content/tensorrt_final_result.mp4')\n",
        "\n",
        "# 8️⃣ 기존 PyTorch 추론도 실행 (비교용)\n",
        "print(\"\\n🐍 PyTorch 기존 추론 (비교용)...\")\n",
        "def pytorch_combined_inference(video_path, output_path='/content/pytorch_result.mp4'):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        base_results = base_model(frame, verbose=False)\n",
        "        custom_results = custom_model(frame, verbose=False)\n",
        "\n",
        "        # 간단한 시각화 (속도 비교용)\n",
        "        annotated_frame = frame.copy()\n",
        "        cv2.putText(annotated_frame, \"PyTorch\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
        "\n",
        "        out.write(annotated_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "        if frame_count >= 100:  # 100프레임만 처리 (비교용)\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    pytorch_fps = frame_count / total_time\n",
        "    return pytorch_fps\n",
        "\n",
        "pytorch_fps = pytorch_combined_inference(video_path)\n",
        "\n",
        "# 9️⃣ 성능 평가 (커스텀 모델)\n",
        "print(\"\\n📊 커스텀 모델 성능 평가:\")\n",
        "metrics = custom_model.val(data='/content/dataset/dataset.yaml')  # custom_trt_model 대신 custom_model\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "\n",
        "# 🔟 최종 결과 및 비교\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎯 최종 성능 비교 결과:\")\n",
        "print(f\"🐍 PyTorch: {pytorch_fps:.1f} FPS\")\n",
        "print(f\"⚡ TensorRT: {tensorrt_fps:.1f} FPS\")\n",
        "print(f\"🚀 전체 속도 향상: {tensorrt_fps/pytorch_fps:.2f}x\")\n",
        "\n",
        "print(f\"\\n📊 모델 정확도 (mAP50): {metrics.box.map50:.4f}\")\n",
        "\n",
        "print(\"\\n🎬 최종 TensorRT 결과 영상:\")\n",
        "Video('/content/tensorrt_final_result.mp4', width=800)\n",
        "\n",
        "print(\"\\n🎉 TensorRT 최적화 완료!\")\n",
        "print(\"🔵 파란색 박스: 기본 YOLO 객체들 (TensorRT 최적화)\")\n",
        "print(\"🔴 빨간색 박스: 커스텀 객체들 (TensorRT 최적화)\")\n",
        "print(\"💚 초록색 텍스트: 실시간 FPS 표시\")\n",
        "\n",
        "print(\"\\n💾 생성된 파일들:\")\n",
        "print(\"- tensorrt_final_result.mp4: TensorRT 최적화된 최종 결과\")\n",
        "print(\"- pytorch_result.mp4: PyTorch 비교용 결과\")\n",
        "print(\"- yolo11n.engine: 기본 모델 TensorRT 엔진\")\n",
        "print(\"- best.engine: 커스텀 모델 TensorRT 엔진\")"
      ],
      "metadata": {
        "id": "PcDhpQri0lOZ",
        "outputId": "a7c4a6b1-0e8a-4382-c5a6-a634b62136ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 TensorRT 최적화 YOLO 추론 시작!\n",
            "============================================================\n",
            "🤖 기본 모델 로드 중...\n",
            "기본 모델 클래스 수: 80\n",
            "커스텀 모델 클래스 수: 2\n",
            "\n",
            "⚡ TensorRT 변환 중...\n",
            "기본 모델 → TensorRT 변환...\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.4s, saved as 'yolo11n.onnx' (10.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.13.0.35...\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 84, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as yolo11n.engine\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 230.9s, saved as 'yolo11n.engine' (8.9 MB)\n",
            "\n",
            "Export complete (231.2s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.engine imgsz=640 half \n",
            "Validate:        yolo val task=detect model=yolo11n.engine imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml half \n",
            "Visualize:       https://netron.app\n",
            "커스텀 모델 → TensorRT 변환...\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/dataset/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.9s, saved as '/content/dataset/best.onnx' (11.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.13.0.35...\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 6, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as /content/dataset/best.engine\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 184.7s, saved as '/content/dataset/best.engine' (8.9 MB)\n",
            "\n",
            "Export complete (185.0s)\n",
            "Results saved to \u001b[1m/content/dataset\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/dataset/best.engine imgsz=640 half \n",
            "Validate:        yolo val task=detect model=/content/dataset/best.engine imgsz=640 data=/content/dataset/dataset.yaml half \n",
            "Visualize:       https://netron.app\n",
            "\n",
            "🔥 TensorRT 모델 로드 중...\n",
            "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
            "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
            "✅ TensorRT 모델 로드 완료!\n",
            "\n",
            "📥 YouTube 영상 다운로드 중...\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=AxLmroTo3rQ\n",
            "[youtube] AxLmroTo3rQ: Downloading webpage\n",
            "[youtube] AxLmroTo3rQ: Downloading tv client config\n",
            "[youtube] AxLmroTo3rQ: Downloading tv player API JSON\n",
            "[youtube] AxLmroTo3rQ: Downloading ios player API JSON\n",
            "[youtube] AxLmroTo3rQ: Downloading m3u8 information\n",
            "[info] AxLmroTo3rQ: Downloading 1 format(s): 18\n",
            "[download] /content/test_video.mp4 has already been downloaded\n",
            "\u001b[K[download] 100% of    7.14MiB\n",
            "✅ 다운로드 완료: /content/test_video.mp4\n",
            "\n",
            "⏱️ 성능 비교 (첫 100프레임)\n",
            "--------------------------------------------------\n",
            "Loading yolo11n.engine for TensorRT inference...\n",
            "Loading /content/dataset/best.engine for TensorRT inference...\n",
            "🐍 PyTorch 평균: 24.25ms/frame (41.2 FPS)\n",
            "⚡ TensorRT 평균: 12.30ms/frame (81.3 FPS)\n",
            "🚀 속도 향상: 1.97x\n",
            "\n",
            "🔥 TensorRT 최적화된 결합 추론 실행...\n",
            "\n",
            "🎬 TensorRT 최적화 영상 처리 중... (총 3990 프레임)\n",
            "   처리 중... 50/3990 (1.3%) - 평균 91.0 FPS\n",
            "   처리 중... 100/3990 (2.5%) - 평균 91.0 FPS\n",
            "   처리 중... 150/3990 (3.8%) - 평균 88.5 FPS\n",
            "   처리 중... 200/3990 (5.0%) - 평균 86.3 FPS\n",
            "   처리 중... 250/3990 (6.3%) - 평균 81.7 FPS\n",
            "   처리 중... 300/3990 (7.5%) - 평균 78.6 FPS\n",
            "   처리 중... 350/3990 (8.8%) - 평균 76.2 FPS\n",
            "   처리 중... 400/3990 (10.0%) - 평균 75.8 FPS\n",
            "   처리 중... 450/3990 (11.3%) - 평균 75.5 FPS\n",
            "   처리 중... 500/3990 (12.5%) - 평균 75.4 FPS\n",
            "   처리 중... 550/3990 (13.8%) - 평균 75.3 FPS\n",
            "   처리 중... 600/3990 (15.0%) - 평균 75.2 FPS\n",
            "   처리 중... 650/3990 (16.3%) - 평균 75.1 FPS\n",
            "   처리 중... 700/3990 (17.5%) - 평균 75.1 FPS\n",
            "   처리 중... 750/3990 (18.8%) - 평균 75.1 FPS\n",
            "   처리 중... 800/3990 (20.1%) - 평균 75.1 FPS\n",
            "   처리 중... 850/3990 (21.3%) - 평균 75.2 FPS\n",
            "   처리 중... 900/3990 (22.6%) - 평균 75.2 FPS\n",
            "   처리 중... 950/3990 (23.8%) - 평균 74.7 FPS\n",
            "   처리 중... 1000/3990 (25.1%) - 평균 74.1 FPS\n",
            "   처리 중... 1050/3990 (26.3%) - 평균 73.6 FPS\n",
            "   처리 중... 1100/3990 (27.6%) - 평균 73.8 FPS\n",
            "   처리 중... 1150/3990 (28.8%) - 평균 74.0 FPS\n",
            "   처리 중... 1200/3990 (30.1%) - 평균 74.3 FPS\n",
            "   처리 중... 1250/3990 (31.3%) - 평균 74.5 FPS\n",
            "   처리 중... 1300/3990 (32.6%) - 평균 74.7 FPS\n",
            "   처리 중... 1350/3990 (33.8%) - 평균 74.9 FPS\n",
            "   처리 중... 1400/3990 (35.1%) - 평균 75.1 FPS\n",
            "   처리 중... 1450/3990 (36.3%) - 평균 75.3 FPS\n",
            "   처리 중... 1500/3990 (37.6%) - 평균 75.5 FPS\n",
            "   처리 중... 1550/3990 (38.8%) - 평균 75.6 FPS\n",
            "   처리 중... 1600/3990 (40.1%) - 평균 75.8 FPS\n",
            "   처리 중... 1650/3990 (41.4%) - 평균 75.9 FPS\n",
            "   처리 중... 1700/3990 (42.6%) - 평균 75.6 FPS\n",
            "   처리 중... 1750/3990 (43.9%) - 평균 75.2 FPS\n",
            "   처리 중... 1800/3990 (45.1%) - 평균 74.8 FPS\n",
            "   처리 중... 1850/3990 (46.4%) - 평균 74.8 FPS\n",
            "   처리 중... 1900/3990 (47.6%) - 평균 74.9 FPS\n",
            "   처리 중... 1950/3990 (48.9%) - 평균 75.0 FPS\n",
            "   처리 중... 2000/3990 (50.1%) - 평균 75.1 FPS\n",
            "   처리 중... 2050/3990 (51.4%) - 평균 75.4 FPS\n",
            "   처리 중... 2100/3990 (52.6%) - 평균 75.6 FPS\n",
            "   처리 중... 2150/3990 (53.9%) - 평균 75.8 FPS\n",
            "   처리 중... 2200/3990 (55.1%) - 평균 76.0 FPS\n",
            "   처리 중... 2250/3990 (56.4%) - 평균 76.1 FPS\n",
            "   처리 중... 2300/3990 (57.6%) - 평균 76.1 FPS\n",
            "   처리 중... 2350/3990 (58.9%) - 평균 76.2 FPS\n",
            "   처리 중... 2400/3990 (60.2%) - 평균 76.2 FPS\n",
            "   처리 중... 2450/3990 (61.4%) - 평균 75.9 FPS\n",
            "   처리 중... 2500/3990 (62.7%) - 평균 75.6 FPS\n",
            "   처리 중... 2550/3990 (63.9%) - 평균 75.3 FPS\n",
            "   처리 중... 2600/3990 (65.2%) - 평균 75.3 FPS\n",
            "   처리 중... 2650/3990 (66.4%) - 평균 75.3 FPS\n",
            "   처리 중... 2700/3990 (67.7%) - 평균 75.3 FPS\n",
            "   처리 중... 2750/3990 (68.9%) - 평균 75.3 FPS\n",
            "   처리 중... 2800/3990 (70.2%) - 평균 75.3 FPS\n",
            "   처리 중... 2850/3990 (71.4%) - 평균 75.3 FPS\n",
            "   처리 중... 2900/3990 (72.7%) - 평균 75.3 FPS\n",
            "   처리 중... 2950/3990 (73.9%) - 평균 75.4 FPS\n",
            "   처리 중... 3000/3990 (75.2%) - 평균 75.4 FPS\n",
            "   처리 중... 3050/3990 (76.4%) - 평균 75.4 FPS\n",
            "   처리 중... 3100/3990 (77.7%) - 평균 75.4 FPS\n",
            "   처리 중... 3150/3990 (78.9%) - 평균 75.2 FPS\n",
            "   처리 중... 3200/3990 (80.2%) - 평균 75.0 FPS\n",
            "   처리 중... 3250/3990 (81.5%) - 평균 74.8 FPS\n",
            "   처리 중... 3300/3990 (82.7%) - 평균 74.8 FPS\n",
            "   처리 중... 3350/3990 (84.0%) - 평균 74.8 FPS\n",
            "   처리 중... 3400/3990 (85.2%) - 평균 74.8 FPS\n",
            "   처리 중... 3450/3990 (86.5%) - 평균 74.8 FPS\n",
            "   처리 중... 3500/3990 (87.7%) - 평균 74.8 FPS\n",
            "   처리 중... 3550/3990 (89.0%) - 평균 74.7 FPS\n",
            "   처리 중... 3600/3990 (90.2%) - 평균 74.7 FPS\n",
            "   처리 중... 3650/3990 (91.5%) - 평균 74.7 FPS\n",
            "   처리 중... 3700/3990 (92.7%) - 평균 74.7 FPS\n",
            "   처리 중... 3750/3990 (94.0%) - 평균 74.7 FPS\n",
            "   처리 중... 3800/3990 (95.2%) - 평균 74.5 FPS\n",
            "   처리 중... 3850/3990 (96.5%) - 평균 74.3 FPS\n",
            "   처리 중... 3900/3990 (97.7%) - 평균 74.2 FPS\n",
            "   처리 중... 3950/3990 (99.0%) - 평균 74.3 FPS\n",
            "✅ TensorRT 결과 영상 저장: /content/tensorrt_final_result.mp4\n",
            "📊 평균 처리 속도: 74.3 FPS\n",
            "\n",
            "🐍 PyTorch 기존 추론 (비교용)...\n",
            "\n",
            "📊 커스텀 모델 성능 평가:\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1794.9±181.2 MB/s, size: 301.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels.cache... 72 images, 0 backgrounds, 0 corrupt: 100%|██████████| 72/72 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         72        569      0.614      0.486      0.478      0.192\n",
            "                  lane         72        497      0.529      0.416      0.433      0.142\n",
            "          traffic_sign         34         72      0.699      0.556      0.523      0.243\n",
            "Speed: 4.8ms preprocess, 3.6ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
            "mAP50: 0.4781\n",
            "\n",
            "============================================================\n",
            "🎯 최종 성능 비교 결과:\n",
            "🐍 PyTorch: 41.5 FPS\n",
            "⚡ TensorRT: 74.3 FPS\n",
            "🚀 전체 속도 향상: 1.79x\n",
            "\n",
            "📊 모델 정확도 (mAP50): 0.4781\n",
            "\n",
            "🎬 최종 TensorRT 결과 영상:\n",
            "\n",
            "🎉 TensorRT 최적화 완료!\n",
            "🔵 파란색 박스: 기본 YOLO 객체들 (TensorRT 최적화)\n",
            "🔴 빨간색 박스: 커스텀 객체들 (TensorRT 최적화)\n",
            "💚 초록색 텍스트: 실시간 FPS 표시\n",
            "\n",
            "💾 생성된 파일들:\n",
            "- tensorrt_final_result.mp4: TensorRT 최적화된 최종 결과\n",
            "- pytorch_result.mp4: PyTorch 비교용 결과\n",
            "- yolo11n.engine: 기본 모델 TensorRT 엔진\n",
            "- best.engine: 커스텀 모델 TensorRT 엔진\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab 시작하기",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}